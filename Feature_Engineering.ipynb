{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1  What is a parameter?\n",
        "\n",
        "\n",
        "Ans-  A parameter is a variable used to define or pass information into a function, method, or system. It acts like a placeholder that allows you to customize how something behaves."
      ],
      "metadata": {
        "id": "QDlf9DSWTsDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2  What is correlation?\n",
        "What does negative correlation mean?\n",
        "\n",
        "Ans   Correlation is a statistical measure that describes the relationship between two variables—specifically, how much they change together\n",
        "\n",
        "\n",
        "Negative correlation: When one variable increases, the other tends to decrease"
      ],
      "metadata": {
        "id": "VxEWuHENTtDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3   Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "Ans   Machine Learning is a branch of artificial intelligence (AI) that enables systems to learn from data and improve their performance on a specific task without being explicitly programmed\n",
        "\n",
        "\n",
        "Main Components of Machine Learning:\n",
        "Data\n",
        "Feature\n",
        "Model\n",
        "Algorithm\n",
        "Training\n",
        "Evaluation"
      ],
      "metadata": {
        "id": "FcLYYLPITuOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4   How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "\n",
        "Ans   The loss value (also called cost) measures how far off a model's predictions are from the actual outcomes. It is a numerical indicator of error.\n",
        "\n",
        "Guides Learning\n",
        "\n",
        "During training, the model uses the loss value to update its parameters\n",
        "\n",
        "Measures Accuracy of Predictions\n",
        "\n",
        "High loss means the model is making large errors"
      ],
      "metadata": {
        "id": "hONq07M8TvXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5  What are continuous and categorical variables?\n",
        "\n",
        "These are numerical variables that can take any value within a range.\n",
        "\n",
        "Characteristics:\n",
        "Can have decimal or fractional values.\n",
        "\n",
        "Can be measured (not just counted).\n",
        "\n",
        "Infinite number of possible values within a range.\n",
        "\n",
        "\n",
        "Categorical Variables\n",
        "These are variables that represent groups or categories.\n",
        "\n",
        "Characteristics:\n",
        "Can take only a limited number of distinct values.\n",
        "\n",
        "Values usually represent labels or names.\n",
        "\n",
        "Can be nominal or ordinal."
      ],
      "metadata": {
        "id": "-tXPomcnTvU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6  How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "Ans  Common Techniques to Handle Categorical Variables:\n",
        "1. Label Encoding\n",
        "Converts each category into a unique integer.\n",
        "\n",
        "Simple, but may imply ordinal relationships that don’t exist.\n",
        "\n",
        "One-Hot Encoding\n",
        "Creates binary (0/1) columns for each category.\n",
        "\n",
        "No ordinal assumption.\n",
        "\n",
        "Ordinal Encoding\n",
        "Similar to Label Encoding, but used when the categories have a meaningful order\n",
        "\n",
        "\n",
        "Target Encoding (Mean Encoding)\n",
        "Replaces a category with the average value of the target variable for that category."
      ],
      "metadata": {
        "id": "2HzKptLrTvR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7   What do you mean by training and testing a dataset?\n",
        "Ans  Training a Dataset\n",
        "This is the learning phase.\n",
        "\n",
        "You give the model input data along with the correct output (labels).\n",
        "\n",
        "The model learns patterns and relationships from this data.\n",
        "\n",
        "\n",
        "\n",
        "Testing a Dataset\n",
        "This is the evaluation phase.\n",
        "\n",
        "You give the model new, unseen data (with known outputs) to check how well it performs.\n",
        "\n",
        "You do not let the model learn from this data — it’s only for assessment.\n",
        "\n",
        "Purpose:\n",
        "To see how well the model can generalize to data it hasn't seen before."
      ],
      "metadata": {
        "id": "6BivI_wyTvOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8   What is sklearn.preprocessing?\n",
        "\n",
        "Ans   sklearn.preprocessing is a module in scikit-learn (a popular Python machine learning library) that provides tools to prepare or transform your data before feeding it into a machine learning model."
      ],
      "metadata": {
        "id": "Ylfda2D3TvLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9   What is a Test set?\n",
        "\n",
        "Ans   test set is a portion of your dataset that you use to evaluate how well your trained machine learning model performs on unseen data"
      ],
      "metadata": {
        "id": "TW8-H36gTvIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10   How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "Ans    from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example data (features X and target y)\n",
        "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
        "y = [0, 1, 0, 1, 0]\n",
        "\n",
        "# Split the data: 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training features:\", X_train)\n",
        "print(\"Testing features:\", X_test)\n",
        "\n",
        "\n",
        "\n",
        "Approach to Solving a Machine Learning Problem\n",
        "Here’s a common workflow to tackle ML projects:\n",
        "\n",
        "Step 1: Understand the Problem\n",
        "What is the goal? (e.g., classify emails as spam or not)\n",
        "\n",
        "What type of problem is it? (classification, regression, clustering, etc.)\n",
        "\n",
        "Step 2: Collect Data\n",
        "\n",
        "Gather a dataset relevant to the problem.\n",
        "\n",
        "Step 3: Explore and Prepare Data\n",
        "Analyze data (summary stats, visualization)\n",
        "\n",
        "Clean data (handle missing values, remove duplicates)\n",
        "\n",
        "Feature engineering (create useful features)\n",
        "\n",
        "Encode categorical variables\n",
        "\n",
        "Scale/normalize features if needed\n",
        "\n",
        "Step 4: Split Data\n",
        "Divide data into training and testing sets (sometimes also validation set).\n",
        "\n",
        "Step 5: Choose a Model\n",
        "Pick appropriate algorithms (e.g., decision tree, logistic regression).\n",
        "\n",
        "Step 6: Train the Model\n",
        "Fit the model on the training data.\n",
        "\n",
        "Step 7: Evaluate the Model\n",
        "Use the test set to check performance using metrics (accuracy, RMSE, F1-score, etc.).\n",
        "\n",
        "Step 8: Tune the Model\n",
        "Optimize hyperparameters using cross-validation or grid search.\n",
        "Step 9: Deploy and Monitor\n",
        "Use the model for predictions in real-world scenarios."
      ],
      "metadata": {
        "id": "7hZaV3mDTvFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11   Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "\n",
        "Ans  Understand Your Data\n",
        "\n",
        "Get a clear picture of the data’s structure, types, and quality.\n",
        "\n",
        "Know what features you have and their distributions.\n",
        "\n",
        "Detect and Handle Issues\n",
        "\n",
        "Identify missing values, outliers, and errors that can mislead the model.\n",
        "\n",
        "Decide how to clean or transform the data accordingly.\n",
        "\n",
        "Find Patterns and Relationships\n",
        "\n",
        "Explore correlations or associations between features and the target.\n",
        "\n",
        "This helps select relevant features or create new ones.\n",
        "\n",
        "Choose the Right Model and Approach\n",
        "\n",
        "Some algorithms work better with certain data types or distributions.\n",
        "\n",
        "EDA guides model selection and preprocessing methods.\n",
        "\n",
        "Improve Model Performance\n",
        "\n",
        "Properly prepared data often leads to more accurate, reliable models"
      ],
      "metadata": {
        "id": "JgPDTxC8TvCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12  What is correlation?\n",
        "\n",
        "Ans Correlation is a statistical measure that describes the relationship between two variables—specifically, how much they change together\n"
      ],
      "metadata": {
        "id": "UO3bpG_HTu_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13  What does negative correlation mean?\n",
        "\n",
        "Ans    \n",
        "Negative correlation: When one variable increases, the other tends to decrease"
      ],
      "metadata": {
        "id": "_90GxoHATu86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14   How can you find correlation between variables in Python?\n",
        "\n",
        "\n",
        "ans\n",
        "\n",
        "Using Pandas .corr() method\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'age': [23, 45, 31, 35, 52],\n",
        "    'income': [50000, 64000, 58000, 60000, 72000],\n",
        "    'score': [80, 95, 78, 88, 92]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "print(correlation_matrix)\n",
        "\n",
        "\n",
        "Visualizing Correlation Matrix (Heatmap)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oKkHPlWaTu6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15   What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "Ans  \n",
        "Causation means one event directly causes another. If A causes B, changing A will produce a change in B.\n",
        "\n",
        "Correlation  \n",
        "\n",
        "Two variables change together\n",
        "No clear cause-effect direction\n",
        "Statistical relationship   \n",
        "Eg-  Ice cream sales and drowning rates rise together\n",
        "\n",
        "\n",
        "Causation\n",
        "\n",
        "One variable causes change in the other\n",
        "Clear cause → effect                               |\n",
        "Requires controlled experiments or strong evidence\n",
        "Eg-  Smoking causes lung cancer                         |"
      ],
      "metadata": {
        "id": "R_-GTAxKTu3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16   What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "\n",
        "Ans     An optimizer is an algorithm used to update the parameters (weights and biases) of a model during training to minimize the loss function. The goal is to find the best set of parameters that make the model's predictions as accurate as possible.\n",
        "\n",
        "Gradient Descent (GD)\n",
        "Description: Uses the entire dataset to compute the gradient of the loss function and update parameters.\n",
        "\n",
        "Pros: Stable updates.\n",
        "\n",
        "Cons: Very slow for large datasets.\n",
        "\n",
        "\n",
        "Stochastic Gradient Descent (SGD)\n",
        "Description: Uses one random sample from the dataset per update.\n",
        "\n",
        "Pros: Faster, more frequent updates, can escape local minima.\n",
        "\n",
        "Cons: Noisy updates, less stable convergence.\n",
        "\n",
        "Example:\n",
        "Instead of waiting to evaluate all data, SGD updates after each single sample.\n",
        "\n",
        "Mini-batch Gradient Descent\n",
        "Description: Uses a small batch (subset) of the data for each update.\n",
        "\n",
        "Pros: Balances speed and stability.\n",
        "\n",
        "Cons: Requires tuning batch size.\n",
        "\n",
        "Example:\n",
        "Using batches of size 32 or 64, it computes gradient on those before updating.\n",
        "\n",
        "\n",
        "\n",
        "Momentum\n",
        "Description: Adds a momentum term to the update to accelerate convergence and reduce oscillations.\n",
        "\n",
        "Pros: Faster convergence, smoother updates.\n",
        "Example:\n",
        "Helps in ravines of the loss surface where gradients oscillate.\n",
        "\n",
        "5. Adagrad (Adaptive Gradient Algorithm)\n",
        "Description: Adapts the learning rate individually for each parameter based on past gradients.\n",
        "\n",
        "Pros: Good for sparse data.\n",
        "\n",
        "Cons: Learning rate shrinks too much over time.\n",
        "\n",
        "Example:\n",
        "Used in natural language processing for sparse features.\n",
        "\n",
        "6. RMSprop (Root Mean Square Propagation)\n",
        "Description: Like Adagrad but fixes its diminishing learning rate problem by using exponential decay average of squared gradients."
      ],
      "metadata": {
        "id": "nxwE9Rb8Tu0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17   What is sklearn.linear_model ?\n",
        "\n",
        "Ans   It contains classes and functions to implement linear algorithms that model the relationship between input features and output targets.\n",
        "\n",
        "These models assume that the target variable is a linear combination of input features, possibly with some noise.\n",
        "\n",
        "It supports both regression (predicting continuous values) and classification (predicting categorical labels) with linear methods."
      ],
      "metadata": {
        "id": "H-jysyhATugn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18   What does model.fit() do? What arguments must be given?\n",
        "\n",
        "\n",
        "Ans  The .fit() method is how you train (or fit) a machine learning model on your data. When you call model.fit(), the model learns the relationship between the input data and the target values by adjusting its parameters (like weights in a linear model) to best fit the data\n",
        "\n",
        "Typically, .fit() requires at least two main arguments:\n",
        "\n",
        "X: Input features (independent variables) — usually a 2D array-like structure, shape (n_samples, n_features).\n",
        "\n",
        "y: Target values (dependent variable) — usually a 1D array-like structure, shape (n_samples,) for regression or classification labels."
      ],
      "metadata": {
        "id": "0dyp3-jcYMYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19  What does model.predict() do? What arguments must be given?\n",
        "\n",
        "Ans   After you’ve trained your model with model.fit(), you use model.predict() to make predictions on new data.\n",
        "\n",
        "It takes input data (features) and outputs the predicted target values based on the model parameters learned during training.\n",
        "\n",
        "It usually takes one required argument:\n",
        "\n",
        "X: The input data (features) for which you want to predict. It should have the same number of features as the training data."
      ],
      "metadata": {
        "id": "AloywU-ZYNXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20   What are continuous and categorical variables?\n",
        "\n",
        "Ans   These are numerical variables that can take any value within a range.\n",
        "\n",
        "Characteristics: Can have decimal or fractional values.\n",
        "\n",
        "Can be measured (not just counted).\n",
        "\n",
        "Infinite number of possible values within a range.\n",
        "\n",
        "Categorical Variables These are variables that represent groups or categories.\n",
        "\n",
        "Characteristics: Can take only a limited number of distinct values.\n",
        "\n",
        "Values usually represent labels or names.\n",
        "\n",
        "Can be nominal or ordinal."
      ],
      "metadata": {
        "id": "8Axov7vcYNUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21    What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Ans   Feature scaling is the process of standardizing or normalizing the range of independent variables (features) in your data. It transforms features so that they have comparable scales or distributions.\n",
        "\n",
        "How does Feature Scaling help in Machine Learning?\n",
        "Faster convergence: Gradient descent converges faster because the contours of the cost function become more circular and well-behaved.\n",
        "\n",
        "Improves performance: Some algorithms perform poorly if features have very different scales.\n",
        "\n",
        "Prevents dominance: Prevents features with large ranges from dominating the learning.\n",
        "\n",
        "Distance-based methods: Algorithms like K-Nearest Neighbors (KNN), K-Means, and Support Vector Machines (SVM) depend on distances, which require features to be scaled to be meaningful."
      ],
      "metadata": {
        "id": "Le569C9DYM33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22  How do we perform scaling in Python?\n",
        "\n",
        "\n",
        "Ans   Step 1: Import the scaler class from sklearn.preprocessing\n",
        "Common scalers:\n",
        "\n",
        "StandardScaler — scales data to zero mean and unit variance\n",
        "\n",
        "MinMaxScaler — scales data to a fixed range (usually 0 to 1)\n",
        "\n",
        "RobustScaler — scales data using median and IQR (good for outliers)\n",
        "\n",
        "Step 2: Fit the scaler on training data and transform it\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load example dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit scaler on training data and transform training data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform test data using the same scaler (do NOT fit again!)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Mean of scaled training data (per feature):\", X_train_scaled.mean(axis=0))\n",
        "print(\"Std of scaled training data (per feature):\", X_train_scaled.std(axis=0))\n",
        "\n",
        "\n",
        "Step 3: Use scaled data for model training and prediction"
      ],
      "metadata": {
        "id": "aSasFzh3Y7jH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23   What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "Ans    sklearn.preprocessing is a module in scikit-learn (a popular Python machine learning library) that provides tools to prepare or transform your data before feeding it into a machine learning model."
      ],
      "metadata": {
        "id": "MwTvXYnNZBFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24   How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "\n",
        "Ans     from sklearn.model_selection import train_test_split\n",
        "\n",
        "Example data (features X and target y)\n",
        "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]] y = [0, 1, 0, 1, 0]\n",
        "\n",
        "Split the data: 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42 )\n",
        "\n",
        "print(\"Training features:\", X_train) print(\"Testing features:\", X_test)\n",
        "\n",
        "Approach to Solving a Machine Learning Problem Here’s a common workflow to tackle ML projects:\n",
        "\n",
        "Step 1: Understand the Problem What is the goal? (e.g., classify emails as spam or not)\n",
        "\n",
        "What type of problem is it? (classification, regression, clustering, etc.)\n",
        "\n",
        "Step 2: Collect Data\n",
        "\n",
        "Gather a dataset relevant to the problem.\n",
        "\n",
        "Step 3: Explore and Prepare Data Analyze data (summary stats, visualization)\n",
        "\n",
        "Clean data (handle missing values, remove duplicates)\n",
        "\n",
        "Feature engineering (create useful features)\n",
        "\n",
        "Encode categorical variables\n",
        "\n",
        "Scale/normalize features if needed\n",
        "\n",
        "Step 4: Split Data Divide data into training and testing sets (sometimes also validation set).\n",
        "\n",
        "Step 5: Choose a Model Pick appropriate algorithms (e.g., decision tree, logistic regression).\n",
        "\n",
        "Step 6: Train the Model Fit the model on the training data.\n",
        "\n",
        "Step 7: Evaluate the Model Use the test set to check performance using metrics (accuracy, RMSE, F1-score, etc.).\n",
        "\n",
        "Step 8: Tune the Model Optimize hyperparameters using cross-validation or grid search. Step 9: Deploy and Monitor Use the model for predictions in real-world scenarios."
      ],
      "metadata": {
        "id": "ZEyAFn7RZE_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25  Explain data encoding?\n",
        "\n",
        "\n",
        "Ans   Data encoding is the process of converting categorical (non-numeric) data into a numeric format that machine learning algorithms can understand.\n",
        "\n",
        "Most machine learning models can't work with text or categories directly — they need numbers. Encoding transforms those categories into numbers without losing their meaning."
      ],
      "metadata": {
        "id": "WkUAJs87ZI2v"
      }
    }
  ]
}